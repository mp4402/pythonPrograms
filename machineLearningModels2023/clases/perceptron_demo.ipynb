{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS 101\n",
    "\n",
    "## Perceptron\n",
    "In __1943__ neuroscientist `Warren McCulloch` and logician `Walter Pitts` published a paper showing how neurons could implement the three logical functions.  The neurons they used were simple threshold neurons (which they named perceptrons).  \n",
    "\n",
    "\n",
    "Perceptron Algorithm (__1958__ by `Frank Rosenblatt`):\n",
    "\n",
    "Prediction (y)    \n",
    "- `1  if Wx+b >= 0`\n",
    "- `0  if Wx+b <  0`\n",
    "\n",
    "Also, the steps in this method are very similar to how Neural Networks learn, which is as follows:\n",
    "- Initialize weight values and bias\n",
    "- Forward Propagate\n",
    "- Check the error\n",
    "- Backpropagate and Adjust weights and bias\n",
    "- Repeat for all training examples\n",
    "\n",
    "In __1969__ a famous book entitled Perceptrons by `Marvin Minsky` and `Seymour Papert` showed that it was impossible for these classes of network to learn an XOR function. It is often believed (incorrectly) that they also conjectured that a similar result would hold for a multi-layer perceptron network. However, this is not true, as both Minsky and Papert already knew that multi-layer perceptrons were capable of producing an XOR function. Nevertheless, the often-miscited __Minsky/Papert__ text caused a significant decline in interest and funding of neural network research. (https://en.wikipedia.org/wiki/Perceptron)\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Perceptrons_(book)#The_XOR_affair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron \n",
    "Class defintition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \"\"\" Implementation of a perceptron\n",
    "\n",
    "    The purpose of this class is to test the perceptron's capabilities to be configured as a logical\n",
    "    gate and to manualy validate the Perceptron Algorithm.\n",
    "\n",
    "    Step threshold is implemented and can be activated using the threshold flag thus applying the \n",
    "    perceptron rule to all outputs:\n",
    "        1 if Wx+b >= 0\n",
    "        0 if Wx+b < 0\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=True):\n",
    "        \"\"\" Initialize perceptron\n",
    "        Args:\n",
    "            threshold (bool): Use threshold step for output\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = np.array([0,0])\n",
    "        self.w = np.array([0,0])\n",
    "        self.b = 0\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        \n",
    "    def set_and(self):\n",
    "        \"\"\" AND gate weights and bias\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = np.array([1,1])\n",
    "        self.b = -1.5\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def set_or(self):\n",
    "        \"\"\" OR gate weights and bias\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = np.array([1,1])\n",
    "        self.b = -1.0\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def set_nor(self):\n",
    "        \"\"\" NOR gate weights and bias\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = np.array([-1,-1])\n",
    "        self.b = 0.5\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def set_nand(self):\n",
    "        \"\"\" NAND gate weights and bias\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = np.array([-1,-1])\n",
    "        self.b = 1\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def set_not(self):\n",
    "        \"\"\" NOT gate weights and bias\n",
    "        \"\"\"\n",
    "\n",
    "        self.w = np.array([-1])\n",
    "        self.b = 0.5\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def ff(self):\n",
    "        \"\"\" Feed Forward the perceptron and return result\n",
    "        \"\"\"\n",
    "\n",
    "        result = np.dot(self.x, self.w)+self.b\n",
    "        if self.threshold:\n",
    "            return int(result >= 0) \n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    \n",
    "    def run_gate(self):\n",
    "        \"\"\" Run all possible values of gate input\n",
    "            and print the results\n",
    "        \"\"\"\n",
    "\n",
    "        print('Input\\tOutput')\n",
    "        if len(self.w) == 2:\n",
    "            for x1 in range(0,2):\n",
    "                for x2 in range(0,2):\n",
    "                    self.x = np.array([x1,x2])\n",
    "                    print('{0}\\t{1:>5}'.format(self.x, self.ff()))\n",
    "                    \n",
    "        elif len(self.w) == 1:\n",
    "            for x1 in range(0,2):\n",
    "                self.x = np.array([x1])\n",
    "                print('{0}\\t{1:>5}'.format(self.x, self.ff()))\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \"\"\"Run input though gate\n",
    "        \"\"\"\n",
    "\n",
    "        self.x = np.array(x)\n",
    "        return self.ff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Perceptron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\tOutput\n",
      "[0 0]\t    0\n",
      "[0 1]\t    0\n",
      "[1 0]\t    0\n",
      "[1 1]\t    1\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron(threshold=True)\n",
    "p.set_and().run_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\tOutput\n",
      "[0 0]\t    0\n",
      "[0 1]\t    1\n",
      "[1 0]\t    1\n",
      "[1 1]\t    1\n"
     ]
    }
   ],
   "source": [
    "p.set_or().run_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\tOutput\n",
      "[0 0]\t    1\n",
      "[0 1]\t    0\n",
      "[1 0]\t    0\n",
      "[1 1]\t    0\n"
     ]
    }
   ],
   "source": [
    "p.set_nor().run_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\tOutput\n",
      "[0]\t    1\n",
      "[1]\t    0\n"
     ]
    }
   ],
   "source": [
    "p.set_not().run_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\tOutput\n",
      "[0 0]\t    1\n",
      "[0 1]\t    1\n",
      "[1 0]\t    1\n",
      "[1 1]\t    0\n"
     ]
    }
   ],
   "source": [
    "p.set_nand().run_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.set_or().predict([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can cascade outputs to other perceptrons\n",
    "# thus able to create (simulate) any logic component\n",
    "inputs = [0,0]\n",
    "x1 = p.set_nor().predict(inputs)\n",
    "x2 = p.set_and().predict(inputs)\n",
    "p.set_or().predict([x1,x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_layer_perceptron():\n",
    "    \"\"\" Multilayer perceptron class based on the Perceptron class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" \n",
    "        x1-\\-/- P1 -|\n",
    "            X       P3 - output\n",
    "        x2-/-\\- P2 -|\n",
    "        \"\"\"\n",
    "        self.p1 = Perceptron()\n",
    "        self.p2 = Perceptron()\n",
    "        self.p3 = Perceptron()\n",
    "\n",
    "        \n",
    "        \n",
    "    def set_xor(self):\n",
    "        \"\"\" Set an XOR configuration\n",
    "        \"\"\"\n",
    "        self.p1 = self.p1.set_nor()\n",
    "        self.p2 = self.p2.set_and()\n",
    "        self.p3 = self.p3.set_nor()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def ff(self):\n",
    "        \"\"\" Propagate input though network of perceptrons\n",
    "        \"\"\"\n",
    "        inputs = [self.x[0], self.x[1]]\n",
    "        x1 = self.p1.predict(inputs)\n",
    "        x2 = self.p2.predict(inputs)\n",
    "        \n",
    "        result = self.p3.predict([x1, x2])        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def run_gate(self):\n",
    "        \"\"\" Run all possible values of gate input\n",
    "            and print the results\n",
    "        \"\"\"\n",
    "\n",
    "        print('Input\\tOutput')\n",
    "\n",
    "        for x1 in range(0,2):\n",
    "            for x2 in range(0,2):\n",
    "                self.x = np.array([x1, x2])\n",
    "                print('{0}\\t{1:>5}'.format(self.x, self.ff()))\n",
    "                    \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \"\"\" Get \n",
    "        \"\"\"\n",
    "        self.x = np.array(x)\n",
    "        print(self.x)\n",
    "        return self.ff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Multi_layer_perceptron().set_xor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\tOutput\n",
      "[0 0]\t    0\n",
      "[0 1]\t    1\n",
      "[1 0]\t    1\n",
      "[1 1]\t    0\n"
     ]
    }
   ],
   "source": [
    "mlp.run_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b91cc7978587585701d9df66399963e42097edb83d30389318cd4ab8d216092b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
